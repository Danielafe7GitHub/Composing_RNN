{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from random import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Glove and  40000 words list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n",
      "400000\n",
      "(400000, 50)\n",
      "closure\n",
      "[ 0.50653   0.12284  -0.11653  -0.21052  -1.0672   -0.17536   0.16253\n",
      "  0.76781   0.25517  -0.15995   0.025424 -0.65425  -0.44638  -0.19395\n",
      "  0.45319   1.0955    0.050096 -0.36712   0.1729    0.28393   0.85448\n",
      " -0.54932  -1.1816    0.066158 -0.58561  -0.84893   0.1947    0.37832\n",
      "  0.94141   0.62982   2.3869   -0.41035  -0.11599   0.049907 -0.41563\n",
      " -0.056999  1.5044   -0.93772  -0.16045   0.80019  -0.44448  -0.50036\n",
      "  0.065875  0.27778  -0.27505  -0.012317 -0.37458   0.49171  -0.35498\n",
      "  0.035347]\n"
     ]
    }
   ],
   "source": [
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')\n",
    "print(len(wordsList))\n",
    "print(wordVectors.shape)\n",
    "print(wordsList[5066])\n",
    "print(wordVectors[5066][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger   How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##\n",
      "Labels:  3960 Sentences:  3960\n"
     ]
    }
   ],
   "source": [
    "#--------------------Extracting Emotion && sentences from corpus\n",
    "def extract(dataset):\n",
    "    f = open(dataset, 'r+', encoding='utf-8')\n",
    "    linea = f.readline()\n",
    "    emotion = []\n",
    "    sentences = []\n",
    "    neutro = re.compile('^ne')\n",
    "    while linea != \"\":    \n",
    "        #Ignoramos Neutro emotions\n",
    "        if not re.match(neutro, linea):\n",
    "            #print(\"** \",linea)\n",
    "            linea = linea.split(\"**@**\")\n",
    "            #Obtaining the emocion\n",
    "            emotion.append(linea[2])\n",
    "            sentences.append(linea[1])\n",
    "        linea = f.readline()\n",
    "    f.close()\n",
    "    return sentences,emotion\n",
    "\n",
    "dataset = \"TwitterDataset/Train/train_valid.txt\"\n",
    "sentences,emotions = extract(dataset)\n",
    "print(emotions[0],\" \",sentences[0])\n",
    "print(\"Labels: \",len(emotions), \"Sentences: \",len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('TwitterDataset/Train/train_valid.csv', mode='w', encoding='utf-8') as emo_file:\n",
    "    emo_writer = csv.writer(emo_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    emo_writer.writerow(['Emotion', 'Sentence'])\n",
    "    for i in range(0,len(emotions)):\n",
    "        emo_writer.writerow([emotions[i],sentences[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion                                           Sentence\n",
       "0   anger  How the fu*k! Who the heck! moved my fridge!.....\n",
       "1   anger  So my Indian Uber driver just called someone t...\n",
       "2   anger  @DPD_UK I asked for my parcel to be delivered ...\n",
       "3   anger  so ef whichever butt wipe pulled the fire alar...\n",
       "4   anger  Don't join @BTCare they put the phone down on ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"TwitterDataset/Train/train_valid.csv\", delimiter=\",\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuánto hay de cada emoción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline\n",
    "def histograma(emotion):\n",
    "    #print(emotion)\n",
    "    plt.hist(emotion, 50)\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axis([0, 4, 0, 1400])\n",
    "    plt.show()\n",
    "histograma(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesing of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    '''phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)'''\n",
    "\n",
    "    if phrase == \"t\":\n",
    "        phrase = \"not\"\n",
    "    elif phrase == \"re\":\n",
    "        phrase = \"are\"\n",
    "    elif phrase == \"s\":\n",
    "        phrase = \"is\"\n",
    "    elif phrase == \"d\":\n",
    "        phrase = \"would\"\n",
    "    elif phrase == \"ve\":\n",
    "        phrase = \"have\"\n",
    "    elif phrase == \"m\":\n",
    "        phrase = \"am\"\n",
    "    elif phrase == \"ca\":\n",
    "        phrase = \"can\"\n",
    "    elif phrase == \"isn\":\n",
    "        phrase = \"is\"\n",
    "    elif phrase == \"aren\":\n",
    "        phrase = \"are\"\n",
    "    elif phrase == \"wouldn\":\n",
    "        phrase = \"would\"\n",
    "    elif phrase == \"don\":\n",
    "        phrase = \"do\"\n",
    "    elif phrase == \"wasn\":\n",
    "        phrase = \"was\"\n",
    "    elif phrase == \"weren\":\n",
    "        phrase = \"were\"\n",
    "\n",
    "    # general\n",
    "    '''phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)'''\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(user_string):\n",
    "    user_string = user_string.lower()\n",
    "    user_string = WordPunctTokenizer().tokenize(user_string)\n",
    "    j = 0\n",
    "    for _str in user_string:\n",
    "        # File path which consists of Abbreviations.\n",
    "        fileName = \"TwitterDataset/slang.txt\"\n",
    "        # File Access mode [Read Mode]\n",
    "        accessMode = \"r\"\n",
    "        with open(fileName, accessMode) as myCSVfile:\n",
    "            # Reading file as CSV with delimiter as \"=\", so that abbreviation are stored in row[0] and phrases in row[1]\n",
    "            dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "            # Removing Special Characters.\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in dataFromFile:\n",
    "                # Check if selected word matches short forms[LHS] in text file.\n",
    "                if _str.upper() == row[0]:\n",
    "                    # If match found replace it with its Abbreviation in text file.\n",
    "                    user_string[j] = row[1].lower()\n",
    "            myCSVfile.close()\n",
    "        j = j + 1\n",
    "    return user_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Cleanning Sentences--------------\n",
    "lem = WordNetLemmatizer()\n",
    "def clean_text(text, remove_stopwords=False):\n",
    "    '''Clean the text, with the option to remove stopwords'''\n",
    "    #Remove @user or http://...\n",
    "    text = re.sub(r\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text) \n",
    "\n",
    "    # Translate OMG to Oh My God\n",
    "    text = translator(text)\n",
    "    #Decontracs\n",
    "    for w in range (0,len(text)):\n",
    "        text[w] = decontracted(text[w])\n",
    "\n",
    "    # Convert words to lower case and split them\n",
    "    #text = text.lower()#.split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"<br />\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    \n",
    "    #Lematize && itertools Ejmp: looove to love\n",
    "    text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "    text = lem.lemmatize(text, \"v\")\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "\n",
    "\n",
    "train_clean = []\n",
    "for sentence in train.Sentence:\n",
    "    train_clean.append(clean_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##\n",
      "how the fu k who the heck moved my fridge should i knock the landlord door angry mad\n",
      "\n",
      "So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted \n",
      "so my indian uber driver just called someone the n word if i was not in a moving vehicle i would have jumped out disgusted\n",
      "\n",
      "@DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice\n",
      "i asked for my parcel to be delivered to a pick up store not my address fuming poorcustomerservice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the cleaned reviews\n",
    "for i in range(3):\n",
    "    print(sentences[i])\n",
    "    print(train_clean[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les't determine the total and average number of words in each sentencesLes't determine the total and average number of words in each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average:  83\n"
     ]
    }
   ],
   "source": [
    "def maximum(sent):\n",
    "    numWords = []\n",
    "    for s in sent:\n",
    "        counter = len(s)\n",
    "        numWords.append(counter) \n",
    "    maxLengh = int(sum(numWords)/len(numWords))\n",
    "    print(\"Average: \", maxLengh)\n",
    "    return numWords,maxLengh\n",
    "numWords,maxSeqLength = maximum(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def histograma(numWords):\n",
    "    plt.hist(numWords, 50)\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axis([0, 70, 0, 500])\n",
    "    plt.show()\n",
    "histograma(numWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting each sentence into a vector and adding it into a matrix of 'ids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integerSenteces(sent,maximum):\n",
    "    i = 0\n",
    "    embbeding = 0\n",
    "    matrix = np.zeros((len(sent), maximum)) #250 X 6 (numEjem X Maximun)\n",
    "    for s in sent:\n",
    "        vector = np.zeros((maximum), dtype='int32')\n",
    "        s =  s.split()\n",
    "        bound = maximum\n",
    "        if len(s) < maximum:\n",
    "            bound = len(s)    \n",
    "        for token in range(0,bound): #No encuentra macu, porque la corta\n",
    "            if s[token] not in wordsList:\n",
    "                vector[token] = embbeding # ???\n",
    "                #---print(s[token])\n",
    "            else:\n",
    "                vector[token] = (wordsList.index(s[token]))\n",
    "                embbeding = vector[token]\n",
    "        matrix[i] = (vector)\n",
    "        i += 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences integer representation:  (3960, 83)\n",
      "Sentences:  3960\n",
      "Integer format:  [8.100e+01 4.300e+01 3.320e+02 5.960e+02 1.318e+03 3.800e+01 4.146e+03\n",
      " 8.100e+01 1.170e+02 4.100e+01 1.190e+02 5.000e+00 1.200e+01 1.920e+02\n",
      " 8.350e+02 4.300e+01 3.000e+01 1.920e+02 5.476e+03 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      "Normal format:  you will never find someone who loved you like i did and that my love will be my revenge\n"
     ]
    }
   ],
   "source": [
    "X = integerSenteces(train_clean,maxSeqLength) \n",
    "print(\"Sentences integer representation: \",(X.shape))\n",
    "print(\"Sentences: \",len(train_clean))\n",
    "print(\"Integer format: \",X[249])\n",
    "print(\"Normal format: \",train_clean[249])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3   How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##\n"
     ]
    }
   ],
   "source": [
    "def toClasses(emo):\n",
    "    id_emo = []\n",
    "    for e in emo:\n",
    "        e = e.split()\n",
    "        e = e[0]\n",
    "        if e == 'joy':\n",
    "            e = 1\n",
    "        elif e == 'sadness':\n",
    "            e = 2\n",
    "        elif e == 'anger':\n",
    "            e = 3\n",
    "        elif e == 'fear':\n",
    "            e = 4\n",
    "            \n",
    "        id_emo.append(e)\n",
    "    return id_emo\n",
    "emotions = toClasses(emotions)\n",
    "print(emotions[0],\" \",sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the Data (stratify) into : Train && Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:  3960   Labels:  3960\n",
      "X_train:  3168   Y_train:  3168   X_test:  792   Y_test:  792\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences: \",len(X),\"  Labels: \",len(emotions))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, emotions, test_size=0.20, random_state=random.randrange(50), stratify=emotions)\n",
    "print(\"X_train: \",len(X_train),\"  Y_train: \",len(Y_train),\"  X_test: \",len(X_test),\"  Y_test: \",len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline\n",
    "def histograma(emotion):\n",
    "    #print(emotion)\n",
    "    plt.hist(emotion, 50)\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axis([0, 4, 0, 1000])\n",
    "    plt.show()\n",
    "histograma(Y_train)\n",
    "print(\"*****************\")\n",
    "histograma(Y_test)\n",
    "#for i in range (0,len(X_train)):\n",
    " #   print(Y_train[i],\"  \",X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the Labels into Onehot Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLabels(emo):\n",
    "    classes = 4\n",
    "    Y = np.zeros((len(emo), classes)) #Num Ejemplos X 4 emociones\n",
    "    for e in range(0,len(emo)):\n",
    "        vector = np.zeros((classes))\n",
    "        vector[(emo[e] % (classes + 1)) - 1] = 1 \n",
    "        Y[e] = vector\n",
    "        #print(emo[e],\"---\",vector)\n",
    "    return Y\n",
    " \n",
    "Y_train = toLabels(Y_train)\n",
    "Y_test = toLabels(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:  (3168, 4)  Num Ejem X # clases\n",
      "X_train:  (3168, 83)  Num Ejem X Maximun Lengh\n",
      "Y_test:  (792, 4)  Num Ejem X # clases\n",
      "X_test:  (792, 83)  Num Ejem X Maximun Lengh\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_train: \",Y_train.shape,\" Num Ejem X # clases\")\n",
    "print(\"X_train: \",X_train.shape,\" Num Ejem X Maximun Lengh\")\n",
    "print(\"Y_test: \",Y_test.shape,\" Num Ejem X # clases\")\n",
    "print(\"X_test: \",X_test.shape,\" Num Ejem X Maximun Lengh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger   At the point today where if someone says something remotely kind to me, a waterfall will burst out of my eyes\n",
      "Labels:  3142 Sentences:  3142\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFYFJREFUeJzt3X+0XWV95/H3x6BisCaC6NCAxh8Z0XGqQlT8VREYRvwFVRl1rKKlZpxirdqZmnZcYtvVitURy+oUjUIF/NH6q8KIIyIKznQEDYgEpZYMIkQooGIAIyLwnT/2c8shXJLzwL33nCTv11pn3b2f/Zyzv/fk5H7OfvY+z0lVIUnSuO4z6QIkSdsWg0OS1MXgkCR1MTgkSV0MDklSF4NDktRl3oIjyYlJrk1y8UjbrknOTHJp+/ng1p4kxyVZn+SiJPuM3OeI1v/SJEfMV72SpPHM5xHHR4Dnbda2GjirqlYAZ7V1gEOAFe22CjgehqABjgaeBjwVOHombCRJkzFvwVFVXwN+slnzocBJbfkk4LCR9pNrcC6wNMkewL8Hzqyqn1TV9cCZ3DWMJEkLaKcF3t/DqupqgKq6OslDW/sy4MqRfhta292130WSVQxHK+yyyy777r333nNcuiRt384///wfVdXuW+u30MFxdzJLW22h/a6NVWuANQArV66stWvXzl11O6Dlq0+/S9vlx7xgApVIWihJfjBOv4W+quqaNgRF+3lta98A7DXSb0/gqi20S5ImZKGD4zRg5sqoI4BTR9pf066u2g/Y2Ia0zgAOTvLgdlL84NYmSZqQeRuqSvIJYH/gIUk2MFwddQzwySRHAlcAh7fuXwCeD6wHNgGvA6iqnyT5U+Cbrd+fVNXmJ9wlSQto3oKjql55N5sOnKVvAUfdzeOcCJw4h6VJku4FPzkuSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4TCY4kb0nynSQXJ/lEkp2TPDLJeUkuTfJ3Se7X+t6/ra9v25dPomZJ0mDBgyPJMuBNwMqqegKwCHgF8G7g2KpaAVwPHNnuciRwfVU9Bji29ZMkTcikhqp2Ah6QZCdgMXA1cADw6bb9JOCwtnxoW6dtPzBJFrBWSdKIBQ+Oqvoh8F7gCobA2AicD/y0qm5t3TYAy9ryMuDKdt9bW//dNn/cJKuSrE2y9rrrrpvfX0KSdmCTGKp6MMNRxCOBXwV2AQ6ZpWvN3GUL2+5oqFpTVSurauXuu+8+V+VKkjYziaGqg4DvV9V1VfVL4LPAM4ClbegKYE/gqra8AdgLoG1fAvxkYUuWJM2YRHBcAeyXZHE7V3Eg8F3gq8DLWp8jgFPb8mltnbb9K1V1lyMOSdLCmMQ5jvMYTnJfAKxrNawB3ga8Ncl6hnMYJ7S7nADs1trfCqxe6JolSXfYaetd5l5VHQ0cvVnzZcBTZ+l7M3D4QtQlSdo6PzkuSepicEiSuhgckqQuEznHMd/W/XAjy1effqe2y495wYSqkaTti0cckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC7b5SfHpWm0+WwG4IwG2jZ5xCFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQufo5D0jbBz8FMD484JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdZlIcCRZmuTTSf4xySVJnp5k1yRnJrm0/Xxw65skxyVZn+SiJPtMomZJ0mCs4EjyhDne718CX6yqvYEnApcAq4GzqmoFcFZbBzgEWNFuq4Dj57gWSVKHcY84PpDkG0l+J8nSe7PDJA8Cfh04AaCqbqmqnwKHAie1bicBh7XlQ4GTa3AusDTJHvemBknSPTdWcFTVs4BXAXsBa5N8PMm/u4f7fBRwHfA3Sb6V5MNJdgEeVlVXt/1dDTy09V8GXDly/w2t7U6SrEqyNsna2zZtvIelSZK2ZuxzHFV1KfB24G3Ac4Dj2jmKl3TucydgH+D4qnoy8DPuGJaaTWYrZ5b61lTVyqpauWjxks6SJEnjGvccx68lOZbhXMQBwIuq6nFt+djOfW4ANlTVeW390wxBcs3MEFT7ee1I/71G7r8ncFXnPiVJc2TcI46/Ai4AnlhVR1XVBQBVdRXDUcjYquqfgSuTPLY1HQh8FzgNOKK1HQGc2pZPA17Trq7aD9g4M6QlSVp4437n+POBn1fVbQBJ7gPsXFWbquqUe7Df3wU+luR+wGXA6xhC7JNJjgSuAA5vfb/Q9r8e2NT6SpImZNzg+DJwEHBTW18MfAl4xj3ZaVVdCKycZdOBs/Qt4Kh7sh9J0twbd6hq56qaCQ3a8uL5KUmSNM3GDY6fjX5iO8m+wM/npyRJ0jQbd6jqzcCnksxczbQH8PL5KUmSNM3GCo6q+maSvYHHMnyu4h+r6pfzWpkkaSqNe8QB8BRgebvPk5NQVSfPS1WSpKk1VnAkOQV4NHAhcFtrLsDgkKQdzLhHHCuBx7dLYyVJO7Bxr6q6GPhX81mIJGnbMO4Rx0OA7yb5BvCLmcaqevG8VCVJmlrjBsc757MISdK2Y9zLcc9J8ghgRVV9OcliYNH8liZJmkbjTqv+eobpzz/YmpYBn5uvoiRJ02vck+NHAc8EboB/+VKnh27xHpKk7dK4wfGLqrplZiXJTszyLXySpO3fuMFxTpI/Ah7Qvmv8U8D/nL+yJEnTatzgWA1cB6wD/hPDlyt1ffOfJGn7MO5VVbcDH2o3SdIObNy5qr7PLOc0qupRc16RJGmq9cxVNWNnhu8D33Xuy5EkTbuxznFU1Y9Hbj+sqvcDB8xzbZKkKTTuUNU+I6v3YTgC+ZV5qUiSNNXGHar67yPLtwKXA/9hzquRJE29ca+qeu58FyJJ2jaMO1T11i1tr6r3zU05kqRp13NV1VOA09r6i4CvAVfOR1GSpOnV80VO+1TVjQBJ3gl8qqp+e74KkyRNp3GnHHk4cMvI+i3A8jmvRpI09cY94jgF+EaSv2f4BPlvACfPW1WSpKk17lVVf5bkfwHPbk2vq6pvzV9ZkqRpNe5QFcBi4Iaq+ktgQ5JHzlNNkqQpNu5Xxx4NvA34w9Z0X+Cj81WUJGl6jXvE8RvAi4GfAVTVVTjliCTtkMYNjluqqmhTqyfZZf5KkiRNs3GD45NJPggsTfJ64Mv4pU6StEMa96qq97bvGr8BeCzwjqo6c14rkyRNpa0GR5JFwBlVdRAwZ2HRHnct8MOqemG7SutvGb4g6gLg1VV1S5L7M3xmZF/gx8DLq+ryuapDktRnq0NVVXUbsCnJkjne9+8Bl4ysvxs4tqpWANcDR7b2I4Hrq+oxwLGtnyRpQsY9x3EzsC7JCUmOm7nd050m2RN4AfDhth6GbxT8dOtyEnBYWz60rdO2H9j6S5ImYNwpR05vt7nyfuAPuOOS3t2An1bVrW19A7CsLS+jzcJbVbcm2dj6/2j0AZOsAlYBLHrQ7nNYqiRp1BaDI8nDq+qKqjppS/16JHkhcG1VnZ9k/5nmWbrWGNvuaKhaA6wBuP8eK+6yXZI0N7Y2VPW5mYUkn5mjfT4TeHGSyxlOhh/AcASyNMlMkO0JXNWWNwB7tRp2ApYAP5mjWiRJnbYWHKPv9h81Fzusqj+sqj2rajnwCuArVfUq4KvAy1q3I4BT2/JpbZ22/Svtw4iSpAnYWnDU3SzPh7cBb02ynuEcxgmt/QRgt9b+VmD1PNchSdqCrZ0cf2KSGxiOPB7QlmnrVVUPujc7r6qzgbPb8mXAU2fpczNw+L3ZjyRp7mwxOKpq0UIVIknaNvR8H4ckSQaHJKmPwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuCx4cSfZK8tUklyT5TpLfa+27JjkzyaXt54Nbe5Icl2R9kouS7LPQNUuS7jCJI45bgd+vqscB+wFHJXk8sBo4q6pWAGe1dYBDgBXttgo4fuFLliTNWPDgqKqrq+qCtnwjcAmwDDgUOKl1Owk4rC0fCpxcg3OBpUn2WOCyJUnNRM9xJFkOPBk4D3hYVV0NQ7gAD23dlgFXjtxtQ2vb/LFWJVmbZO1tmzbOZ9mStEObWHAkeSDwGeDNVXXDlrrO0lZ3aahaU1Urq2rlosVL5qpMSdJmJhIcSe7LEBofq6rPtuZrZoag2s9rW/sGYK+Ru+8JXLVQtUqS7mwSV1UFOAG4pKreN7LpNOCItnwEcOpI+2va1VX7ARtnhrQkSQtvpwns85nAq4F1SS5sbX8EHAN8MsmRwBXA4W3bF4DnA+uBTcDrFrZcSdKoBQ+Oqvo/zH7eAuDAWfoXcNS8FiVJGpufHJckdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSl20mOJI8L8n3kqxPsnrS9UjSjmqbCI4ki4D/ARwCPB54ZZLHT7YqSdoxbRPBATwVWF9Vl1XVLcDfAodOuCZJ2iGlqiZdw1YleRnwvKr67bb+auBpVfXGkT6rgFVt9QnAxQte6PbrIcCPJl3EdsTnc+74XM6tR1TV7lvrtNNCVDIHMkvbnRKvqtYAawCSrK2qlQtR2I7A53Nu+XzOHZ/LydhWhqo2AHuNrO8JXDWhWiRph7atBMc3gRVJHpnkfsArgNMmXJMk7ZC2iaGqqro1yRuBM4BFwIlV9Z0t3GXNwlS2w/D5nFs+n3PH53ICtomT45Kk6bGtDFVJkqaEwSFJ6mJw7OCSvCnJJUk+NulatjdJ/u+ka9ieJFmexM9nTYFt4uT4QkgShnM+t0+6lgX2O8AhVfX9e/oASRZV1W1zWNN2oaqeMekapPkw9UccST6X5Pwk32mfDifJTUn+LMm3k5yb5GGt/dFt/ZtJ/iTJTSOP819b+0VJ/ri1LW/vtv8auIA7f1Zku5fkA8CjgNOS/LckJ7bn6FtJDm19lif530kuaLdntPb9k3w1yceBdRP8NaZWe50myXuSXJxkXZKXt22nzDzHbf1jSV48uWoXTpJdkpze/v9enOTlSd7RXnsXJ1nT3siRZN/W7+vAUSOP8dokn03yxSSXJvmLkW0HJ/l6e71+KskDW/sxSb7b/ga8t7Ud3vb57SRfW+CnYttVVVN9A3ZtPx/AMI3IbgyfGn9Ra/8L4O1t+fPAK9vyG4Cb2vLBDJfthSEsPw/8OrAcuB3Yb9K/5wSf38sZpm34c+A3W9tS4J+AXYDFwM6tfQWwti3vD/wMeOSkf4dpvQE3AS8FzmS4jPxhwBXAHsBzgM+1fkuA7wM7TbrmBXpeXgp8aGR9ycz/87Z+ysj/74uA57Tl9wAXt+XXApe1++4M/IDhjd9DgK8Bu7R+bwPeAewKfI87riRd2n6uA5aNtnnb+m3qjziANyX5NnAuwwtjBXALwx9/gPMZAgDg6cCn2vLHRx7j4Hb7FsORxd7tcQB+UFXnzlfx25CDgdVJLgTOZvjP+HDgvsCHkqxjeG5HZyX+Rt2LIa4dxLOAT1TVbVV1DXAO8JSqOgd4TJKHAq8EPlNVt06y0AW0DjgoybuTPLuqNgLPTXJee50dAPybJEsY/pif0+53ymaPc1ZVbayqm4HvAo8A9mN4jf5Dey0f0dpvAG4GPpzkJcCm9hj/AHwkyesZwl1jmOpzHEn2Bw4Cnl5Vm5KczfAH7ZfV3iIAt7H13yPAu6rqg5s9/nKGd80anqOXVtX37tSYvBO4Bngiw9HazSObfe62brZ51macAryKYSaE31qYciavqv4pyb7A84F3JfkSwzDUyqq6sr3mdmZ47rb0QbNfjCzP/B0IcGZVvXLzzkmeChzI8Hy/ETigqt6Q5GnAC4ALkzypqn58r3/J7dy0H3EsAa5vobE3w7uJLTmX4TAYhhfHjDOA3xoZ61zW3unpDmcAvzsytvzk1r4EuLqGiwZeje/Ken0NeHmSRUl2Zxgi/Ubb9hHgzQC15ZkQtitJfhXYVFUfBd4L7NM2/aj9H30ZQFX9FNiY5Flt+6vGePhzgWcmeUzb1+Ik/7o97pKq+gLDc/6ktv3RVXVeVb2DYZbdHeo85z011UccwBeBNyS5iGF8cmtDSm8GPprk94HTgY0AVfWlJI8Dvt7+Lt4E/CbDuxQN/hR4P3BRC4/LgRcCfw18JsnhwFfxKKNHAX/PMIT67bb+B1X1zwBVdU2SS4DPTa7Eifi3wHuS3A78EvjPwGEMQ1iXM8xNN+N1wIlJNjG8udmiqrouyWuBTyS5f2t+O3AjcGqSmSOZt7Rt70myorWdxfDvpK3YrqYcSbIY+HlVVZJXMJwo9wuftOCS7AZcUFWP2EKfxQx/LPdp4/zSNmHajzh67Qv8VXvH/FN2oHFjTY82FHM2wzDM3fU5CDgReJ+hoW3NdnXEIUmaf9N+clySNGUMDklSF4NDktTF4JC2IsltSS4cua2eg8dcnuQ/jqyvTHLcvX1caSF4clzaiiQ3VdUD5/gx9wf+S1W9cC4fV1oIHnFI91CSy5P8eZuJdW2SfZKckeT/JXlD6zPr7LjAMcCz2xHMWzLMNvz5dp9dM8wKfVGG2Z5/rbW/M8MMxmcnuSzJmybzm2tHt719jkOaDw9oE+bNeFdV/V1bvrKqnp7kWIYpRJ7JMM/Sd4APAC9hmN7iiQwzt36zTd+9mpEjjnYEMuOPgW9V1WFJDgBObo8BwwSdzwV+BfhekuOr6pdz/QtLW2JwSFv386p60t1sO639XAc8sKpuBG5McnOSpYzMjgtck+Qc4CkMs7XenWfR5lyrqq8k2a3NFAtwelX9AvhFkmsZpmrfcK9+O6mTQ1XSvTMzQ+vt3Hm21tu5Y7bWXrPdZ+Zk5GwzwkoLyuCQ5tfdzY57I8Nw093d51XwL0NYP6qqLR2hSAvKdyvS1m1+juOLVTXuJbmzzo6b5MfAre1Lyj7C8CVjM94J/E2bFXoTw5cRSVPDy3ElSV0cqpIkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVKX/w+92UhdSGuYMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the point today where if someone says something remotely kind to me, a waterfall will burst out of my eyes\n",
      "at the point today where if someone says something remotely kind to me a waterfall will burst out of my eyes\n",
      "\n",
      "@CorningFootball  IT'S GAME DAY!!!!      T MINUS 14:30  #relentless\n",
      "it is game day not minus  relentless\n",
      "\n",
      "This game has pissed me off more than any other game this year. My blood is boiling! Time to turn it off! #STLCards\n",
      "this game has pissed me off more than any other game this year my blood is boiling time to turn it off stlcards\n",
      "\n",
      "Average:  83\n",
      "Average:  83\n",
      "Sentences integer representation:  (3142, 83)\n",
      "Sentences:  3142\n",
      "Integer format:  [1.8120e+03 4.0000e+00 1.4960e+03 8.3700e+02 9.6740e+03 2.2000e+01\n",
      " 6.5400e+02 1.2000e+01 2.2135e+04 8.1000e+01 2.0000e+01 1.4000e+01\n",
      " 4.8620e+03 4.0000e+00 1.6900e+02 5.1210e+03 2.2000e+01 6.9000e+01\n",
      " 3.8140e+03 3.8140e+03 5.1210e+03 3.5910e+03 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "Normal format:  note to self stop laughing at things that offend you it is ok to get mad at people n notetoself mad upset\n",
      "3   [2.20000e+01 2.01534e+05 3.89000e+02 3.73000e+02 1.11000e+02 8.30000e+01\n",
      " 1.31800e+03 2.10000e+02 6.45000e+02 1.85740e+04 9.21000e+02 4.00000e+00\n",
      " 2.85000e+02 7.00000e+00 1.85010e+04 4.30000e+01 6.30500e+03 6.60000e+01\n",
      " 3.00000e+00 1.92000e+02 2.25100e+03 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      "Y_train:  (3142, 4)  Num Ejem X # clases\n",
      "X_train:  (3142, 83)  Num Ejem X Maximun Lengh\n"
     ]
    }
   ],
   "source": [
    "#Importing Dataset\n",
    "dataset = \"TwitterDataset/Test/testDataset.txt\"\n",
    "test_sentences,test_emotions = extract(dataset)\n",
    "print(test_emotions[0],\" \",test_sentences[0])\n",
    "print(\"Labels: \",len(test_emotions), \"Sentences: \",len(test_sentences))\n",
    "\n",
    "#Converting data to CVS\n",
    "import csv\n",
    "with open('TwitterDataset/Test/test.csv', mode='w', encoding='utf-8') as emo_file:\n",
    "    emo_writer = csv.writer(emo_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    emo_writer.writerow(['Emotion', 'Sentence'])\n",
    "    for i in range(0,len(test_emotions)):\n",
    "        emo_writer.writerow([test_emotions[i],test_sentences[i]])\n",
    "\n",
    "#Examinaiting the data\n",
    "test = pd.read_csv(\"TwitterDataset/Test/test.csv\", delimiter=\",\")\n",
    "test.head()\n",
    "\n",
    "histograma(test_emotions)\n",
    "\n",
    "#Cleanning the data\n",
    "test_clean = []\n",
    "for sentence in test.Sentence:\n",
    "    test_clean.append(clean_text(sentence))\n",
    "    \n",
    "# Inspect the cleaned reviews\n",
    "for i in range(3):\n",
    "    print(test_sentences[i])\n",
    "    print(test_clean[i])\n",
    "    print()\n",
    "    \n",
    "#Find the maximun sequence of words in test dataset\n",
    "numWords,testmaxSeqLength = maximum(test_clean)\n",
    "test_X = integerSenteces(test_clean,testmaxSeqLength)\n",
    "print(\"Average: \",testmaxSeqLength)\n",
    "print(\"Sentences integer representation: \",(test_X.shape))\n",
    "print(\"Sentences: \",len(test_clean))\n",
    "print(\"Integer format: \",test_X[249])\n",
    "print(\"Normal format: \",test_clean[249])\n",
    "\n",
    "#Transforming Labels From Happy to 1\n",
    "test_emotions = toClasses(test_emotions)\n",
    "print(test_emotions[0],\" \",test_X[0])\n",
    "\n",
    "#Transforming Labels from 1 to [1,0,0,0]\n",
    "test_Y = toLabels(test_emotions)\n",
    "\n",
    "print(\"Y_train: \",test_Y.shape,\" Num Ejem X # clases\")\n",
    "print(\"X_train: \",test_X.shape,\" Num Ejem X Maximun Lengh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random X_test split\n",
    "#x_train, y_train = train_test_split(test_X, test_Y, test_size=0.1, random_state=random.randrange(50), stratify=test_Y)\n",
    "#Flata!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:  (3142, 4)  Num Ejem X # clases\n",
      "X_train:  (3142, 83)  Num Ejem X Maximun Lengh\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_train: \",test_Y.shape,\" Num Ejem X # clases\")\n",
    "print(\"X_train: \",test_X.shape,\" Num Ejem X Maximun Lengh\")\n",
    "#for i in range (0,len(x_test)):\n",
    " #   print(y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn(numClasses, maxSeqLength, numDimensions, batchSize, lstmUnits, dropout, learning_rate):\n",
    "    '''Build the Recurrent Neural Network'''\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    with tf.name_scope('inputs'):\n",
    "        inputs = tf.placeholder(tf.int32, [None, maxSeqLength],name='inputs')\n",
    "        \n",
    "    \n",
    "    with tf.name_scope('labels'):\n",
    "        labels = tf.placeholder(tf.float32, [None, numClasses],name='labels')\n",
    "    \n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    # Create the embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "        data = tf.nn.embedding_lookup(wordVectors,inputs)\n",
    "\n",
    "    # Build the RNN layers\n",
    "    with tf.name_scope(\"RNN_layers\"):\n",
    "        lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "        lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=keep_prob)\n",
    "       \n",
    "    # Set the initial state\n",
    "    with tf.name_scope(\"RNN_init_state\"):\n",
    "        initial_state = lstmCell.zero_state(batchSize, tf.float32)\n",
    "\n",
    "    # Run the data through the RNN layers\n",
    "    with tf.name_scope(\"RNN_forward\"):  \n",
    "        value, final_state = tf.nn.dynamic_rnn(lstmCell, data, initial_state=initial_state)\n",
    "     \n",
    "    # Create the fully connected layers\n",
    "    with tf.name_scope(\"fully_connected\"):\n",
    "        \n",
    "        # Initialize the weights and biases\n",
    "        weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "        value = tf.transpose(value, [1, 0, 2])\n",
    "        last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "       \n",
    "        \n",
    "    # Make the predictions\n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = (tf.matmul(last, weight) + bias)\n",
    "        tf.summary.histogram('prediction', prediction)\n",
    "    \n",
    "    # Calculate the cost\n",
    "    with tf.name_scope('cost'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=labels))\n",
    "        tf.summary.scalar('cost', cost)\n",
    "        \n",
    "    \n",
    "    # Train the model\n",
    "    with tf.name_scope('train'):    \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Determine the accuracy\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        \n",
    "        correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))       \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        \n",
    "    \n",
    "    # Merge all of the summaries\n",
    "    merged = tf.summary.merge_all()    \n",
    "\n",
    "    # Export the nodes \n",
    "    export_nodes = ['inputs', 'labels','keep_prob', 'initial_state', 'final_state', 'accuracy',\n",
    "                    'prediction', 'cost', 'optimizer', 'merged']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainning && Validation Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, log_string):\n",
    "    '''Train the RNN'''\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Used to determine when to stop the training early\n",
    "        valid_loss_summary = []\n",
    "        \n",
    "        # Metrics Presicion, recall and F1 measure\n",
    "        val_pre = []\n",
    "        val_recall = []\n",
    "        val_f1 = []\n",
    "        \n",
    "        # Keep track of which batch iteration is being trained\n",
    "        iteration = 0\n",
    "\n",
    "        print()\n",
    "        print(\"Training Model: {}\".format(log_string))\n",
    "\n",
    "        train_writer = tf.summary.FileWriter('./logs/3/train/{}'.format(log_string), sess.graph)\n",
    "        valid_writer = tf.summary.FileWriter('./logs/3/valid/{}'.format(log_string))\n",
    "\n",
    "        for e in range(epochs):\n",
    "            state = sess.run(model.initial_state)\n",
    "            \n",
    "            # Record progress with each epoch\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            val_acc = []\n",
    "            val_loss = []\n",
    "            \n",
    "            #Create X groups of (50,6) Labels && (50,maximum) Examples\n",
    "            numEjemplos = 3168  \n",
    "            total_batch = int(numEjemplos/batchSize)\n",
    "            X_batches = np.array_split(X_train, total_batch)\n",
    "            Y_batches = np.array_split(Y_train, total_batch)\n",
    "\n",
    "            #Train Cycle\n",
    "            with tqdm(total=len(X_train)) as pbar: #Barra de progreso !!!\n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                    feed = {model.inputs: batch_x,\n",
    "                            model.labels: batch_y,\n",
    "                            model.keep_prob: dropout,\n",
    "                            model.initial_state: state}\n",
    "                    summary, loss, acc, state, _ = sess.run([model.merged, \n",
    "                                                             model.cost, \n",
    "                                                             model.accuracy, \n",
    "                                                             model.final_state, \n",
    "                                                             model.optimizer], \n",
    "                                                            feed_dict=feed)\n",
    "\n",
    "                    # Record the loss and accuracy of each training batch\n",
    "                    train_loss.append(loss)\n",
    "                    train_acc.append(acc)\n",
    "                    \n",
    "                    # Record the progress of training\n",
    "                    train_writer.add_summary(summary, iteration)\n",
    "                    \n",
    "                    iteration += 1\n",
    "                    pbar.update(batchSize)\n",
    "            \n",
    "            # Average the training loss and accuracy of each epoch\n",
    "            avg_train_loss = np.mean(train_loss)\n",
    "            avg_train_acc = np.mean(train_acc) \n",
    "\n",
    "            #Create X train batchs of batchSize\n",
    "            numEjemplos = 792  \n",
    "            total_batch = int(numEjemplos/batchSize)\n",
    "            \n",
    "            X_batches = np.array_split(X_test, total_batch)\n",
    "            Y_batches = np.array_split(Y_test, total_batch)\n",
    "            \n",
    "            if e < 88:\n",
    "            # Print the progress of each epoch\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                        \"Train Loss: {:.3f}\".format(avg_train_loss),\n",
    "                        \"Train Acc: {:.3f}\".format(avg_train_acc))\n",
    "\n",
    "                \n",
    "            #Valid Cycle : Solo Valid, en las dos últimas iteraciones\n",
    "            else:\n",
    "                val_state = sess.run(model.initial_state)\n",
    "                with tqdm(total=len(X_test)) as pbar:\n",
    "                    for i in range(total_batch):\n",
    "                        batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                        feed = {model.inputs: batch_x,\n",
    "                                model.labels: batch_y,\n",
    "                                model.keep_prob: 1,\n",
    "                                model.initial_state: val_state}\n",
    "                        summary, batch_loss, batch_acc, val_state, batch_pre = sess.run([model.merged, \n",
    "                                                                              model.cost, \n",
    "                                                                              model.accuracy, \n",
    "                                                                              model.final_state,\n",
    "                                                                              model.prediction], \n",
    "                                                                             feed_dict=feed)\n",
    "\n",
    "\n",
    "                        #Converting predictions to np.array \n",
    "                        y_pred = tf.argmax(batch_pre , 1).eval({model.inputs: batch_x, model.labels: batch_y})\n",
    "                        y_true = (tf.argmax(batch_y , 1).eval()) \n",
    "                        precision = precision_score(y_true, y_pred, average=None)\n",
    "                        recall = recall_score(y_true, y_pred, average=None)\n",
    "                        f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "                        # Record the validation loss and accuracy of each epoch\n",
    "                        val_loss.append(batch_loss)\n",
    "                        val_acc.append(batch_acc)\n",
    "                        val_pre.append(precision)\n",
    "                        val_recall.append(recall)\n",
    "                        val_f1.append(f1)\n",
    "                        pbar.update(batchSize)\n",
    "\n",
    "\n",
    "\n",
    "                # Average the validation loss and accuracy of each epoch\n",
    "                avg_valid_loss = np.mean(val_loss)    \n",
    "                avg_valid_acc = np.mean(val_acc)\n",
    "                valid_loss_summary.append(avg_valid_loss)\n",
    "                avg_pre = np.mean(val_pre)\n",
    "                avg_recall = np.mean(val_recall)\n",
    "                avg_f1 = np.mean(val_f1)\n",
    "\n",
    "                # Record the validation data's progress\n",
    "                valid_writer.add_summary(summary, iteration)\n",
    "\n",
    "\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                \"Train Loss: {:.3f}\".format(avg_train_loss),\n",
    "                \"Train Acc: {:.3f}\".format(avg_train_acc),\n",
    "                \"Valid Loss: {:.3f}\".format(avg_valid_loss),\n",
    "                \"Valid Acc: {:.3f}\".format(avg_valid_acc),\n",
    "                \"Valid Pre: {:.3f}\".format(avg_pre),\n",
    "                \"Valid Reca: {:.3f}\".format(avg_recall),\n",
    "                \"Valid F1: {:.3f}\".format(avg_f1))\n",
    "                \n",
    "                class_names = [\"Hapinnes\",\"Sadness\",\"Anger\",\"Fear\"]\n",
    "                print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "                \n",
    "            checkpoint = \"C:/Users/UX310UQ/Desktop/CheckPoints/sentiment_{}.ckpt\".format(log_string)\n",
    "            saver.save(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarando placeholders para los labels (6 emotions) && data imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default parameters of the model\n",
    "numDimensions = 300 \n",
    "batchSize = 88 #Tiene que ser multiplo del NumEjem\n",
    "lstmUnits = 64\n",
    "numClasses = 4\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: ru=7,fcl=10,fcu=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:06<00:00, 669.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Train Loss: 1.378 Train Acc: 0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 788.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 1.378 Train Acc: 0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 805.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 Train Loss: 1.377 Train Acc: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 790.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Train Loss: 1.377 Train Acc: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 683.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 Train Loss: 1.377 Train Acc: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 793.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 Train Loss: 1.377 Train Acc: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:04<00:00, 706.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 Train Loss: 1.376 Train Acc: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:06<00:00, 731.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 Train Loss: 1.377 Train Acc: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2376/3168 [00:03<00:01, 637.26it/s]"
     ]
    }
   ],
   "source": [
    "log_string = 'ru={},fcl={},fcu={}'.format(7,10,96)\n",
    "model = build_rnn(numClasses = numClasses,\n",
    "                              maxSeqLength=maxSeqLength,\n",
    "                              numDimensions=numDimensions,\n",
    "                              batchSize = batchSize,\n",
    "                              lstmUnits = lstmUnits,\n",
    "                              dropout = dropout,\n",
    "                              learning_rate = learning_rate)       \n",
    "train(model, epochs, log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hacer ultimo chekpoint . en base a F1 \n",
    "Probar con Stop words y otras mod.\n",
    "Limpiar #poorattention\n",
    "@@ estas haciendo valid con batch pqueño , no con todo el gigante, pero no importan en el test se hace asi\n",
    "pondras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 3141 #Habra solo 1 batchs de  3141 ejempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(checkpoint):\n",
    "    '''Predict the sentiment of the testing data'''\n",
    "    \n",
    "    # Record all of the predictions\n",
    "    all_preds = []\n",
    "\n",
    "    model = build_rnn(numClasses = numClasses,\n",
    "                                  maxSeqLength=testmaxSeqLength,\n",
    "                                  numDimensions=numDimensions,\n",
    "                                  batchSize = batchSize,\n",
    "                                  lstmUnits = lstmUnits,\n",
    "                                  dropout = dropout,\n",
    "                                  learning_rate = learning_rate)  \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        # Load the model\n",
    "        saver.restore(sess, checkpoint)\n",
    "        test_state = sess.run(model.initial_state)\n",
    "        \n",
    "        #numEjemplos = 3141  \n",
    "        #total_batch = int(numEjemplos/batchSize)\n",
    "            \n",
    "        #X_batches = np.array_split(X_test, total_batch)\n",
    "        #Y_batches = np.array_split(Y_test, total_batch)\n",
    "        '''print(\"Y_train: \",test_Y.shape,\" Num Ejem X # clases\")\n",
    "        print(\"X_train: \",test_X.shape,\" Num Ejem X Maximun Lengh\")\n",
    "        \n",
    "        X_batches = test_X[:88]\n",
    "        Y_batches = test_Y[:88]\n",
    "        \n",
    "        print(\"Y_batches: \",Y_batches.shape,\" Num Ejem X # clases\")\n",
    "        print(\"X_batches: \",X_batches.shape,\" Num Ejem X Maximun Lengh\")\n",
    "        \n",
    "        feed = {model.inputs: X_batches,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: test_state}\n",
    "        \n",
    "        predictions = sess.run(model.prediction, feed_dict=feed)\n",
    "        \n",
    "        Y = (tf.argmax(Y_batches , 1).eval()) \n",
    "        \n",
    "        Y_pred = tf.argmax(predictions , 1).eval()\n",
    "        \n",
    "        for p in range (0,len(Y_pred)):\n",
    "            print(Y[p],\" \",Y_pred[p])\n",
    "            all_preds.append((Y_pred))'''\n",
    "        \n",
    "            \n",
    "        '''for i in range(total_batch):\n",
    "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            feed = {model.inputs: batch_x,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: test_state}\n",
    "            predictions = sess.run(model.prediction, feed_dict=feed)\n",
    "            Y = (tf.argmax(batch_y , 1).eval()) \n",
    "            Y_pred = tf.argmax(predictions , 1).eval()\n",
    "            for p in range (0,len(Y_pred)):\n",
    "                print(Y[p],\" \",Y_pred[p])\n",
    "                all_preds.append((Y_pred))'''\n",
    "                \n",
    "                \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 = \"C:/Users/UX310UQ/Desktop/CheckPoints/sentiment_ru=7,fcl=10,fcu=96.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/UX310UQ/Desktop/CheckPoints/sentiment_ru=7,fcl=10,fcu=96.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [3141,83,300] rhs shape= [88,83,300]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embeddings/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embeddings/Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-195-5f87938c8171>\", line 2, in <module>\n    predictions1 = make_predictions(checkpoint1)\n  File \"<ipython-input-193-cb3d9b33c9cb>\", line 16, in make_predictions\n    saver = tf.train.Saver()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 494, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 185, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3141,83,300] rhs shape= [88,83,300]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embeddings/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embeddings/Variable, save/RestoreV2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3141,83,300] rhs shape= [88,83,300]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embeddings/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embeddings/Variable, save/RestoreV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-5f87938c8171>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions using the best 3 models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-193-cb3d9b33c9cb>\u001b[0m in \u001b[0;36mmake_predictions\u001b[1;34m(checkpoint)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mtest_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1802\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3141,83,300] rhs shape= [88,83,300]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embeddings/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embeddings/Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-195-5f87938c8171>\", line 2, in <module>\n    predictions1 = make_predictions(checkpoint1)\n  File \"<ipython-input-193-cb3d9b33c9cb>\", line 16, in make_predictions\n    saver = tf.train.Saver()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 494, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 185, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 283, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\UX310UQ\\Anaconda3\\envs\\IaTopicos\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3141,83,300] rhs shape= [88,83,300]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embeddings/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embeddings/Variable, save/RestoreV2)]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best 3 models\n",
    "predictions1 = make_predictions(checkpoint1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def board(sess):\n",
    "    tf.summary.scalar('Loss', loss)\n",
    "    tf.summary.scalar('Accuracy', accuracy)\n",
    "    tf.summary.histogram(\"Histogrma/hAccu\", accuracy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    logdir = \"board/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    return merged,writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance Counter({4: 1257, 3: 941, 1: 902, 2: 860})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "print('Balance',Counter(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#Banlancea ADASYN\n",
    "X_balance, Y_balance = ADASYN().fit_sample(X,emotions)\n",
    "print('Balance',Counter(Y_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7836, 15)   (7836,)\n",
      "3695   3695\n"
     ]
    }
   ],
   "source": [
    "print(X_balance.shape,\" \",Y_balance.shape)\n",
    "print(len(X),\" \",len(emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  6817   Y_train:  6817   X_test:  1019   Y_test:  1019\n"
     ]
    }
   ],
   "source": [
    "X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(X_balance, Y_balance, test_size=0.13, random_state=random.randrange(50), stratify=Y_balance)\n",
    "print(\"X_train: \",len(X_train_b),\"  Y_train: \",len(Y_train_b),\"  X_test: \",len(X_test_b),\"  Y_test: \",len(Y_test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_b = toLabels(Y_train_b)\n",
    "Y_test_b = toLabels(Y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro Modelo: Solo balanceamos Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averogua ottros modelos\n",
    "#Cambie el keep_drop\n",
    "#Cambia learning rate\n",
    "#Cambie num unidades 128?\n",
    "#Prueba con tu modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, log_string):\n",
    "    '''Train the RNN'''\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Used to determine when to stop the training early\n",
    "        valid_loss_summary = []\n",
    "        \n",
    "        # Metrics Presicion, recall and F1 measure\n",
    "        val_pre = []\n",
    "        val_recall = []\n",
    "        val_f1 = []\n",
    "        \n",
    "        # Keep track of which batch iteration is being trained\n",
    "        iteration = 0\n",
    "\n",
    "        print()\n",
    "        print(\"Training Model: {}\".format(log_string))\n",
    "\n",
    "        train_writer = tf.summary.FileWriter('./logs/3/train/{}'.format(log_string), sess.graph)\n",
    "        valid_writer = tf.summary.FileWriter('./logs/3/valid/{}'.format(log_string))\n",
    "\n",
    "        for e in range(epochs):\n",
    "            state = sess.run(model.initial_state)\n",
    "            \n",
    "            # Record progress with each epoch\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            val_acc = []\n",
    "            val_loss = []\n",
    "            \n",
    "            #Create X groups of (50,6) Labels && (50,maximum) Examples\n",
    "            numEjemplos = 3168  \n",
    "            total_batch = int(numEjemplos/batchSize)\n",
    "            X_batches = np.array_split(X_train, total_batch)\n",
    "            Y_batches = np.array_split(Y_train, total_batch)\n",
    "\n",
    "            #Train Cycle\n",
    "            with tqdm(total=len(X_train)) as pbar: #Barra de progreso !!!\n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                    feed = {model.inputs: batch_x,\n",
    "                            model.labels: batch_y,\n",
    "                            model.keep_prob: dropout,\n",
    "                            model.initial_state: state}\n",
    "                    summary, loss, acc, state, _ = sess.run([model.merged, \n",
    "                                                             model.cost, \n",
    "                                                             model.accuracy, \n",
    "                                                             model.final_state, \n",
    "                                                             model.optimizer], \n",
    "                                                            feed_dict=feed)\n",
    "\n",
    "                    # Record the loss and accuracy of each training batch\n",
    "                    train_loss.append(loss)\n",
    "                    train_acc.append(acc)\n",
    "                    \n",
    "                    # Record the progress of training\n",
    "                    train_writer.add_summary(summary, iteration)\n",
    "                    \n",
    "                    iteration += 1\n",
    "                    pbar.update(batchSize)\n",
    "            \n",
    "            # Average the training loss and accuracy of each epoch\n",
    "            avg_train_loss = np.mean(train_loss)\n",
    "            avg_train_acc = np.mean(train_acc) \n",
    "\n",
    "            #Create X train batchs of batchSize\n",
    "            numEjemplos = 792  \n",
    "            total_batch = int(numEjemplos/batchSize)\n",
    "            \n",
    "            X_batches = np.array_split(X_test, total_batch)\n",
    "            Y_batches = np.array_split(Y_test, total_batch)\n",
    "                \n",
    "            #Valid Cycle\n",
    "            val_state = sess.run(model.initial_state)\n",
    "            with tqdm(total=len(X_test)) as pbar:\n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                    feed = {model.inputs: batch_x,\n",
    "                            model.labels: batch_y,\n",
    "                            model.keep_prob: 1,\n",
    "                            model.initial_state: val_state}\n",
    "                    summary, batch_loss, batch_acc, val_state, batch_pre = sess.run([model.merged, \n",
    "                                                                          model.cost, \n",
    "                                                                          model.accuracy, \n",
    "                                                                          model.final_state,\n",
    "                                                                          model.prediction], \n",
    "                                                                         feed_dict=feed)\n",
    "                    \n",
    "                    \n",
    "                    #Converting predictions to np.array \n",
    "                    y_pred = tf.argmax(batch_pre , 1).eval({model.inputs: batch_x, model.labels: batch_y})\n",
    "                    y_true = (tf.argmax(batch_y , 1).eval()) \n",
    "                    precision = precision_score(y_true, y_pred, average=None)\n",
    "                    recall = recall_score(y_true, y_pred, average=None)\n",
    "                    f1 = f1_score(y_true, y_pred, average=None)\n",
    "                    \n",
    "                    # Record the validation loss and accuracy of each epoch\n",
    "                    val_loss.append(batch_loss)\n",
    "                    val_acc.append(batch_acc)\n",
    "                    val_pre.append(precision)\n",
    "                    val_recall.append(recall)\n",
    "                    val_f1.append(f1)\n",
    "                    pbar.update(batchSize)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            # Average the validation loss and accuracy of each epoch\n",
    "            avg_valid_loss = np.mean(val_loss)    \n",
    "            avg_valid_acc = np.mean(val_acc)\n",
    "            valid_loss_summary.append(avg_valid_loss)\n",
    "            avg_pre = np.mean(val_pre)\n",
    "            avg_recall = np.mean(val_recall)\n",
    "            avg_f1 = np.mean(val_f1)\n",
    "            \n",
    "            # Record the validation data's progress\n",
    "            valid_writer.add_summary(summary, iteration)\n",
    "\n",
    "            # Print the progress of each epoch\n",
    "            print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                  \"Train Loss: {:.3f}\".format(avg_train_loss),\n",
    "                  \"Train Acc: {:.3f}\".format(avg_train_acc),\n",
    "                  \"Valid Loss: {:.3f}\".format(avg_valid_loss),\n",
    "                  \"Valid Acc: {:.3f}\".format(avg_valid_acc))\n",
    "\n",
    "            if e > 148:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                \"Train Loss: {:.3f}\".format(avg_train_loss),\n",
    "                \"Train Acc: {:.3f}\".format(avg_train_acc),\n",
    "                \"Valid Loss: {:.3f}\".format(avg_valid_loss),\n",
    "                \"Valid Acc: {:.3f}\".format(avg_valid_acc),\n",
    "                \"Valid Pre: {:.3f}\".format(avg_pre),\n",
    "                \"Valid Reca: {:.3f}\".format(avg_recall),\n",
    "                \"Valid F1: {:.3f}\".format(avg_f1))\n",
    "                \n",
    "                class_names = [\"Hapinnes\",\"Sadness\",\"Anger\",\"Fear\"]\n",
    "                print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "                \n",
    "            # Stop training if the validation loss does not decrease after 3 epochs\n",
    "            if avg_valid_loss > min(valid_loss_summary):\n",
    "                print(\"No Improvement.\")\n",
    "                #-----stop_early += 1\n",
    "                if stop_early == 3:\n",
    "                    break   \n",
    "            \n",
    "            # Reset stop_early if the validation loss finds a new low\n",
    "            # Save a checkpoint of the model\n",
    "            else:\n",
    "                print(\"New Record!\")\n",
    "                stop_early = 0\n",
    "                checkpoint = \"C:/Users/UX310UQ/Desktop/CheckPoints/sentiment_{}.ckpt\".format(log_string)\n",
    "                saver.save(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
